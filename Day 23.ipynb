{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a583c742",
   "metadata": {},
   "source": [
    "Dimensionality Reduction Using Feature Selection\t\n",
    "\n",
    "->Feature selection is the process of reducing the number of input variables when developing a predictive model\n",
    "\n",
    "Common input variable data types: numerical (height) & categorical (such as label)\n",
    "\n",
    "a.Numerical Variables \n",
    "b.Integer Variables. \n",
    "c.Floating Point Variables.\n",
    "d.Categorical Variables. \n",
    "e.Boolean Variables (dichotomous).\n",
    "f.Ordinal Variables. \n",
    "g.Nominal Variables.\n",
    "\n",
    "    Numerical Feature Variance:\n",
    "    ->This is a regression predictive modeling problem with numerical input variables\n",
    "    ->The most common techniques are to use a correlation coefficient, such as Pearson’s for a linear correlation, or rank-based methods for a nonlinear correlation.\n",
    "    \n",
    "    a.Pearson’s correlation coefficient (linear).\n",
    "    b.Spearman’s rank coefficient (nonlinear)\n",
    "    \n",
    "\tBinary Feature Variance\n",
    "\tHighly Correlated Features\n",
    "\tRemoving Irrelevant Features\n",
    "\tRecursively Eliminating Features\n",
    "Model Evaluation\t\n",
    "    Introduction\n",
    "\tCross-Validating Models\n",
    "\tCreating a Baseline Regression Model\n",
    "\tCreating a Baseline Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5900a479",
   "metadata": {},
   "source": [
    "\n",
    "#Overfitting - Over training of training data  --> New dataset -> It will not predict \n",
    "\n",
    "#Handle overfitting by Regularization regression: \n",
    "\n",
    "#L1 Regularization --> 0 (Ridge)\n",
    "#L2 Regularization  ---> near by 0 (Lasso)\n",
    "#Elastic net  -> L1 & L2\n",
    "\n",
    "\n",
    "#Handle overfitting by Regularization classification: \n",
    "\n",
    "#L1 Regularization \n",
    "#L2 Regularization  \n",
    "#Dropout\n",
    "#early stopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b71e6221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 4\n",
      "Selected Features: [ True  True False False False  True  True False]\n",
      "Feature Ranking: [1 1 3 4 5 1 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bjawa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression # --> Classification problem\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "model = LogisticRegression()\n",
    "rfe= RFE(model,n_features_to_select=4,step=1 )\n",
    "fit=rfe.fit(X,Y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d5814f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True False False False False False]\n",
      "[1 1 1 1 1 6 4 3 2 5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "selector = selector.fit(X, y)\n",
    "print(selector.support_)\n",
    "print(selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251dc74e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
