{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d9e4a7e",
   "metadata": {},
   "source": [
    "Dimensionality Reduction Using Feature Selection\t\n",
    "\n",
    "->Feature selection is the process of reducing the number of input variables when developing a predictive model\n",
    "\n",
    "Common input variable data types: numerical (height) & categorical (such as label)\n",
    "\n",
    "a.Numerical Variables \n",
    "b.Integer Variables. \n",
    "c.Floating Point Variables.\n",
    "d.Categorical Variables. \n",
    "e.Boolean Variables (dichotomous).\n",
    "f.Ordinal Variables. \n",
    "g.Nominal Variables.\n",
    "\n",
    "    Numerical Feature Variance:\n",
    "    ->This is a regression predictive modeling problem with numerical input variables\n",
    "    ->The most common techniques are to use a correlation coefficient, such as Pearson’s for a linear correlation, or rank-based methods for a nonlinear correlation.\n",
    "    \n",
    "    a.Pearson’s correlation coefficient (linear).\n",
    "    b.Spearman’s rank coefficient (nonlinear)\n",
    "    \n",
    "\tBinary Feature Variance\n",
    "\tHighly Correlated Features\n",
    "\tRemoving Irrelevant Features\n",
    "\tRecursively Eliminating Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b67d09",
   "metadata": {},
   "source": [
    "\n",
    "#Overfitting - Over training of training data  --> New dataset -> It will not predict \n",
    "\n",
    "#Handle overfitting by Regularization regression: \n",
    "\n",
    "#L1 Regularization --> 0 (Ridge)\n",
    "#L2 Regularization  ---> near by 0 (Lasso)\n",
    "#Elastic net  -> L1 & L2\n",
    "\n",
    "\n",
    "#Handle overfitting by Regularization classification: \n",
    "\n",
    "#L1 Regularization \n",
    "#L2 Regularization  \n",
    "#Dropout\n",
    "#early stopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c1589c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 4\n",
      "Selected Features: [ True  True False False False  True  True False]\n",
      "Feature Ranking: [1 1 3 4 5 1 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bjawa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression # --> Classification problem\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "\n",
    "model = LogisticRegression()\n",
    "rfe= RFE(model,n_features_to_select=4,step=1 )\n",
    "fit=rfe.fit(X,Y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4374a655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True False False False False False]\n",
      "[1 1 1 1 1 6 4 3 2 5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "selector = selector.fit(X, y)\n",
    "print(selector.support_)\n",
    "print(selector.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6844dc20",
   "metadata": {},
   "source": [
    "Model Evaluation\t\n",
    "    Introduction\n",
    "\tCross-Validating Models\n",
    "    -> Leave one out\n",
    "    -> Leave p out\n",
    "    -> P out\n",
    "    -> K-fold\n",
    "    refer : https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\tCreating a Baseline Regression Model\n",
    "\tCreating a Baseline Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "527ee1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "[0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "0.9800000000000001 0.016329931618554516\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=0)\n",
    "X_train.shape, y_train.shape\n",
    "X_test.shape, y_test.shape\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "score=clf.score(X_test, y_test)\n",
    "print(score.mean())\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56fce4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a Baseline Regression Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "y = cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "clf = LogisticRegression(max_iter=10000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "632f1221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "#Creating a Baseline Classification Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "y = cancer.target\n",
    "#print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "classifier = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "print(classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8a9fac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
